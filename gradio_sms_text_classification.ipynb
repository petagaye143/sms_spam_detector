{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (0.26.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (3.8.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.7-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.7/51.7 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "     ---------------------------------------- 0.0/125.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 125.2/125.2 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.0-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio) (2.0.7)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2023.10.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.20.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\peta-\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 14.2 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 16.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/12.6 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.2/12.6 MB 18.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.3/12.6 MB 19.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.6 MB 17.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.4/12.6 MB 17.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.6 MB 18.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.6 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.9/12.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "   ---------------------------------------- 0.0/318.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 318.7/318.7 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 417.5/417.5 kB 13.1 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.7-cp311-none-win_amd64.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.3/137.3 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "   ---------------------------------------- 0.0/423.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 423.9/423.9 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.20.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.4/1.9 MB 25.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 17.4 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.6.0-py3-none-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/8.7 MB 18.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.1/8.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/8.7 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.0/8.7 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.3/8.7 MB 17.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.3/8.7 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.7 MB 18.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.2/8.7 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "   ---------------------------------------- 0.0/93.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 93.2/93.2 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.0/72.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, ffmpy, annotated-types, uvicorn, starlette, pydantic, huggingface-hub, typer, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.112.1 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 huggingface-hub-0.24.5 orjson-3.10.7 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.38.2 tomlkit-0.12.0 typer-0.12.3 uvicorn-0.30.6 websockets-12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Peta-\\anaconda3\\Lib\\site-packages\\~ydantic'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import the required dependencies from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Set the column width to view the text message data.\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "# Import Gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms_classification(sms_text_df):\n",
    "    \"\"\"\n",
    "    Perform SMS classification using a pipeline with TF-IDF vectorization and Linear Support Vector Classification.\n",
    "\n",
    "    Parameters:\n",
    "    - sms_text_df (pd.DataFrame): DataFrame containing 'text_message' and 'label' columns for SMS classification.\n",
    "\n",
    "    Returns:\n",
    "    - text_clf (Pipeline): Fitted pipeline model for SMS classification.\n",
    "\n",
    "    This function takes a DataFrame with 'text_message' and 'label' columns, splits the data into\n",
    "    training and testing sets, builds a pipeline with TF-IDF vectorization and Linear Support Vector\n",
    "    Classification, and fits the model to the training data. \n",
    "    The fitted pipeline is returned to make future predictions.\n",
    "    \"\"\"\n",
    "    # Set the features variable to the text message column.\n",
    "    X = sms_text_df[\"text_message\"]\n",
    "    \n",
    "    # Set the target variable to the \"label\" column.\n",
    "    y = sms_text_df[\"label\"]\n",
    "\n",
    "    # Split data into training and testing and set the test_size = 33%\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, y, random_state = 1, test_size = .33)\n",
    "\n",
    "    # Build a pipeline to transform the test set to compare to the training set.\n",
    "    text_clf = Pipeline([(\"tfidf\", TfidfVectorizer(stop_words = \"english\")), (\"clf\", LinearSVC())])\n",
    "\n",
    "    # Fit the model to the transformed training data and return model.\n",
    "    return text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                  text_message  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "sms_text_df = pd.read_csv(\"Resources/SMSSpamCollection.csv\")\n",
    "sms_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;clf&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;clf&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the sms_classification function with the DataFrame and set the result to the \"text_clf\" variable\n",
    "text_clf = sms_classification(sms_text_df)\n",
    "text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called `sms_prediction` that takes in the SMS text and predicts the whether the text is \"not spam\" or \"spam\". \n",
    "# The function should return the SMS message, and say whether the text is \"not spam\" or \"spam\".\n",
    "def sms_prediction(text):\n",
    "    \"\"\"\n",
    "    Predict the spam/ham classification of a given text message using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text message to be classified.\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating whether the text message is classified as spam or not.\n",
    "\n",
    "    This function takes a text message and a pre-trained pipeline model, then predicts the\n",
    "    spam/ham classification of the text. The result is a message stating whether the text is\n",
    "    classified as spam or not.\n",
    "    \"\"\"\n",
    "    # Create a variable that will hold the prediction of a new text.\n",
    "    predictions = text_clf.predict([text])\n",
    "    \n",
    "    # Using a conditional if the prediction is \"ham\" return the message:\n",
    "    # f'The text message: \"{text}\", is not spam.' Else, return f'The text message: \"{text}\", is spam.'\n",
    "    if predictions[0] == \"ham\":\n",
    "        return f\"The text message {text} is not spam\"\n",
    "    else:\n",
    "        return f\"The text message {text} is spam\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sms_app that takes a textbox for the inputs and has a textbox for the output.  \n",
    "sms_app = gr.Interface(\n",
    "fn = sms_prediction, \n",
    "inputs = [gr.Textbox(label = \"What is the text message you want to test?\")], \n",
    "outputs = gr.Textbox(lines = 4, label = \"Our app has determined: \")\n",
    ")\n",
    "# Povide labels for each textbox. \n",
    "\n",
    "    \n",
    "# Launch the app.\n",
    "sms_app.launch(show_error= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the following text messages. \n",
    "\n",
    "---\n",
    "\n",
    "1. You are a lucky winner of $5000!\n",
    "2. You won 2 free tickets to the Super Bowl.\n",
    "3. You won 2 free tickets to the Super Bowl text us to claim your prize.\n",
    "4. Thanks for registering. Text 4343 to receive free updates on medicare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
